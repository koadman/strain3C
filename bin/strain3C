#!/usr/bin/env nextflow
/* 
 * workflow to resolve strain genomes from an assembly graph
 * using Hi-C data to link the variants in each strain
 */

params.maxstrains = 30
params.replicates = 5
params.strain_count_replicates = 3
// ignore strains below this relative abundance. TODO: choose a smart value for this based on contig coverage
params.abundance_noise_threshold = 0.005

gfa1 = Channel.fromPath(params.gfa)
gfa2 = Channel.fromPath(params.gfa)
bam = Channel.fromPath(params.bam)
vcf = Channel.fromPath(params.vcf)
vcf_tbi = Channel.fromPath(params.vcf+'.tbi')

process bam_per_contig {
input:
	file(gfa) from gfa1
	file(bam) from bam
output:
	file('*.bam') into contig_bams mode('flatten')
	file('id_map.json') into contig_ID_map
"""
bam_per_contig.py ${gfa} ${bam} id_map.json
"""
}

process variants_per_contig {
input:
	file(gfa) from gfa2
	file(bam) from contig_bams
	file(vcf) from vcf
	file(vcf_tbi) from vcf_tbi
	file(id_map) from contig_ID_map
output:
	file("contig*.json") into standat mode('flatten')
	file("contig*.json") into standat2 mode('flatten')
"""
CONTIG=`basename ${bam} .bam`
 get_arcs.py ${gfa} ${vcf} ${bam} ${id_map} \$CONTIG
"""
}

process estimate_strain_counts {
input:
	file(stanjson) from standat
	each rep from Channel.from(1..params.strain_count_replicates)
output:
	set file('*.csv') into strain_estimate_out
"""
BNAME=`basename ${stanjson} .json`
add_straincount.py ${stanjson} ${params.maxstrains} \$BNAME.${rep}.json
genotypes3C variational adapt engaged=0 eta=1 tol_rel_obj=0.001 output_samples=1000 data file=\$BNAME.${rep}.json output file=${stanjson}.${rep}.csv
"""
}

strain_estimate_out.map{ f1 -> [f1.getName().toString().split('.standat.')[0], f1] }.groupTuple().set{ strain_count_models }

//strain_count_models = strain_estimate_out.collect()
process get_strain_count {
input:
	set contig_name,file('*') from strain_count_models
output:
	set contig_name,file('strain_count.txt') into strain_count_file
"""
 select_strain_count.R *.csv ${params.abundance_noise_threshold}
"""
}

standat2.map{ f1 -> [f1.getName().toString().split('.standat.')[0], f1] }.groupTuple().set{ standat3 }
strain_count_file.join(standat3).set{ scsd }

process infer_contig_haplotypes {
input:
	set contig_name, file(esc), file(stanjson) from scsd
	each rep from Channel.from(1..params.replicates)
output:
	file('*.csv') into model_out
"""
KKK=`cat ${esc}`
let KKKm=\$KKK-1
let KKKp=\$KKK+2
BNAME=`basename ${stanjson} .json`
for K in \$(eval echo "{\$KKKm..\$KKKp}")
do
    add_straincount.py ${stanjson} \$K \$BNAME.\$K.json
    genotypes3C variational adapt engaged=0 eta=1 tol_rel_obj=0.001 output_samples=100 data file=\$BNAME.\$K.json output file=${stanjson}.\$K.${rep}.csv
done
"""
}

all_models = model_out.collect()
process best_contig_models {
input:
	file(strain_models) from all_models
output:
	file('*best') into best_model
"""
select_model.R ${strain_models}
cp `cat best_model.txt` `cat best_model.txt`.best
"""
}



